{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "%%configure \n{\n    \"script_location\": \"s3://shivam-trial-s3/code_artefacts/glue/scripts/\",\n    \"--TempDir\": \"s3://shivam-trial-s3/code_artefacts/glue/temp/\"\n}",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.8 \nThe following configurations have been updated: {'script_location': 's3://shivam-trial-s3/code_artefacts/glue/scripts/', '--TempDir': 's3://shivam-trial-s3/code_artefacts/glue/temp/'}\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 15\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 2\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.8 \nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 15 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 2\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 2\nIdle Timeout: 15\nSession ID: 33f55cf5-0db2-4580-be4c-dc1b060a959b\nApplying the following default arguments:\n--glue_kernel_version 1.0.8\n--enable-glue-datacatalog true\nWaiting for session 33f55cf5-0db2-4580-be4c-dc1b060a959b to get into ready status...\nSession 33f55cf5-0db2-4580-be4c-dc1b060a959b has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql import *\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "user_df = spark.sql(\"SELECT * FROM stage.stage_user\")\ncontent_df = spark.sql(\"SELECT * FROM stage.stage_content\")\nevent_df = spark.sql(\"SELECT * FROM stage.stage_event\")\n\nuser_segmentation = spark.sql(\"SELECT * FROM mart.mart_user_segmentation\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "a = jan_users_segmented.filter(jan_users_segmented.user_segment.isNull())\na.show(truncate=False)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 19,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------+----------+------------+\n|deviceid|install_dt|user_segment|\n+--------+----------+------------+\n+--------+----------+------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Users installing app on January 2024\njan_users = user_df.filter((user_df.install_dt >= \"2024-01-01\") & (user_df.install_dt < \"2024-02-01\")).select(\"deviceid\", \"install_dt\")\n\n# User Segmentation for January Users\njan_users_segmented = jan_users.join(user_segmentation.select(\"deviceid\",\"user_segment\"),\"deviceid\",\"inner\")\n\n# All events related to January 2024 devices\njan_events = event_df.join(jan_users_segmented,\"deviceid\",\"inner\")\n\n# Convert eventtimestamp to date column for Day wise metrics\nevent_with_date = jan_events.withColumn(\"event_date\", to_date(col(\"eventtimestamp\")))\n\n# Date difference for events from installed date\nevent_with_diff = event_with_date.withColumn(\"days_after_install\", datediff(event_with_date.event_date, event_with_date.install_dt))\n\n# Events for D0, D1, D3 and D7 metrics\nfiltered_days = event_with_diff.filter(event_with_diff.days_after_install.isin(0, 1, 3, 7)).select(\"deviceid\", \"user_segment\", \"days_after_install\").distinct()\n\n# D0 users corresponding to all users who installed in Jan 2024. Adding them in case they never returned to app after installing it.\nd0_users = jan_users_segmented.select(\"deviceid\", \"user_segment\").distinct()\n\n# Join D0 users with filtered_days for D1, D3, D7 and group by user_segment\nretention_by_segment = d0_users.join(filtered_days, [\"deviceid\", \"user_segment\"], \"inner\") \\\n    .groupBy(\"user_segment\").agg(\n        countDistinct(\"deviceid\").alias(\"D0\"),\n        countDistinct(when(col(\"days_after_install\") == 1, col(\"deviceid\"))).alias(\"D1\"),\n        countDistinct(when(col(\"days_after_install\") == 3, col(\"deviceid\"))).alias(\"D3\"),\n        countDistinct(when(col(\"days_after_install\") == 7, col(\"deviceid\"))).alias(\"D7\")\n    )\n\n# Calculate the rates & keep in order\nretention_rates = retention_by_segment.withColumns({\n    \"D0_rate\": lit(100.0),\n    \"D1_rate\": round((col(\"D1\") / col(\"D0\")) * 100, 2),\n    \"D3_rate\": round((col(\"D3\") / col(\"D0\")) * 100, 2),\n    \"D7_rate\": round((col(\"D7\") / col(\"D0\")) * 100, 2)}).orderBy(\"user_segment\")\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "retention_rates.show(truncate=False)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 20,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------------+-----+-----+-----+-----+-------+-------+-------+-------+\n|user_segment              |D0   |D1   |D3   |D7   |D0_rate|D1_rate|D3_rate|D7_rate|\n+--------------------------+-----+-----+-----+-----+-------+-------+-------+-------+\n|Content Readers - English |29   |28   |29   |27   |100.0  |96.55  |100.0  |93.1   |\n|Content Readers - Hindi   |4    |4    |4    |4    |100.0  |100.0  |100.0  |100.0  |\n|Loyal Users - English     |14321|13694|13561|13538|100.0  |95.62  |94.69  |94.53  |\n|Loyal Users - Hindi       |2359 |2299 |2288 |2263 |100.0  |97.46  |96.99  |95.93  |\n|Notification Engagers     |1    |1    |1    |1    |100.0  |100.0  |100.0  |100.0  |\n|Occasional Users - English|17020|7262 |4228 |2398 |100.0  |42.67  |24.84  |14.09  |\n|Occasional Users - Hindi  |3422 |1514 |828  |431  |100.0  |44.24  |24.2   |12.59  |\n|Other                     |4344 |3796 |3486 |3189 |100.0  |87.38  |80.25  |73.41  |\n|Social Sharers - English  |6    |6    |5    |6    |100.0  |100.0  |83.33  |100.0  |\n|Social Sharers - Hindi    |1    |1    |1    |1    |100.0  |100.0  |100.0  |100.0  |\n+--------------------------+-----+-----+-----+-----+-------+-------+-------+-------+\n",
					"output_type": "stream"
				}
			]
		}
	]
}